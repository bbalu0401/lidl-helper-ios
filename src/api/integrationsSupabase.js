import OpenAI from "openai"
import { supabase } from "./supabaseClient"

const openai = new OpenAI({
  apiKey: import.meta.env.VITE_OPENAI_API_KEY,
  dangerouslyAllowBrowser: true // frontenden is haszn√°lhat√≥
})

// üîπ F√°jl felt√∂lt√©s Supabase Storage-be
export async function uploadFileToStorage(file, bucket = 'uploads') {
  const fileName = `${Date.now()}-${file.name}`
  const { data, error } = await supabase.storage.from(bucket).upload(fileName, file)
  if (error) throw error
  const { data: urlData } = supabase.storage.from(bucket).getPublicUrl(fileName)
  return urlData.publicUrl
}

// üîπ OCR + AI elemz√©s
export async function extractDataWithOpenAI(fileUrl, jsonSchema) {
  const prompt = `
  A k√∂vetkez≈ë k√©pr≈ël struktur√°lt adatot k√©rek a megadott JSON schema alapj√°n:
  ${JSON.stringify(jsonSchema, null, 2)}
  V√°lasz kiz√°r√≥lag JSON form√°tumban legyen!
  K√©p: ${fileUrl}
  `

  const response = await openai.chat.completions.create({
    model: "gpt-4o-mini",
    messages: [
      { role: "system", content: "Te egy OCR √©s adatkinyer≈ë asszisztens vagy." },
      { role: "user", content: prompt }
    ],
    temperature: 0.1
  })

  try {
    const text = response.choices[0].message.content
    const json = JSON.parse(text)
    return { status: "success", output: json }
  } catch (err) {
    console.error("Parse error:", err)
    return { status: "error", output: null }
  }
}

// üîπ Sz√∂veges LLM h√≠v√°s
export async function invokeLLM(prompt) {
  const response = await openai.chat.completions.create({
    model: "gpt-4o-mini",
    messages: [{ role: "user", content: prompt }]
  })
  return response.choices[0].message.content
}

// üîπ K√©p gener√°l√°s (pl. bor√≠t√≥hoz)
export async function generateImage(prompt) {
  const response = await openai.images.generate({
    model: "gpt-image-1",
    prompt,
    size: "1024x1024"
  })
  return response.data[0].url
}
